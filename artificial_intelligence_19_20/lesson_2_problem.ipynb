{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LESSON 2: Informed Search Strategies\n",
    "\n",
    "In the second session we will work on informed search\n",
    "\n",
    "### Maze Environments\n",
    "The environments used is **SmallMaze** (visible in the figure).\n",
    "\n",
    "<img src=\"images/maze.png\" width=\"300\">\n",
    "\n",
    "The agent starts in cell $(0, 2)$ and has to reach the treasure in $(4, 3)$.\n",
    "\n",
    "### Priority Queue\n",
    "\n",
    "You will need a queue ordered by priority as queue, or **PriorityQueue**. The difference between the other versions of queue is that in **PriorityQueue** nodes are removed from the queue based on the current lowest value. In particular, **Node** has two useful parameters (other than those used in the previous session):\n",
    "\n",
    "- pathcost - the path cost from the root node to the current one (defaults to 0)\n",
    "- value - value of a node. Used by PriorityQueue to order its content (defaults to 0)\n",
    "\n",
    "Here is an example of usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 1\n",
      "Added: 2\n",
      "Added: 3\n",
      "Removed: 1\n",
      "Removed: 3\n",
      "Removed: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../tools'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.ai_lab_functions import *\n",
    "\n",
    "# Create 3 nodes for state ids 1 2 3\n",
    "node_1 = Node(1) # No parent, pathcost=0, value=0\n",
    "node_2 = Node(2, node_1, node_1.pathcost + 1, 10) # Child of node_1, pathcost=1, value=10\n",
    "node_3 = Node(3, node_1, 100, 5)  # Child of node_1, pathcost=100, value=5\n",
    "\n",
    "p_queue = PriorityQueue()\n",
    "for n in (node_1, node_2, node_3):\n",
    "    p_queue.add(n)\n",
    "    print(\"Added: {}\".format(n.state))\n",
    "\n",
    "while not p_queue.is_empty():\n",
    "    print(\"Removed: {}\".format(p_queue.remove().state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the order in which nodes are removed from the queue.\n",
    "\n",
    "### Uniform-Cost Search (UCS)\n",
    "Before moving to informed search it is useful to see another uninformed search algorithm: the Uniform-Cost Search (UCS). In the following you can see the implementation in tree search version. Cost of performing an action is supposd to be 1 (also in the assignements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "Solution: [(0, 1), (1, 1), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import envs\n",
    "from utils.ai_lab_functions import build_path\n",
    "\n",
    "\n",
    "def ucs(environment):\n",
    "    \"\"\"\n",
    "    Uniform-cost search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        path: solution as a path\n",
    "    \"\"\"\n",
    "    queue = PriorityQueue()\n",
    "    queue.add(Node(environment.startstate))\n",
    "    while True:\n",
    "        if queue.is_empty():\n",
    "            return None\n",
    "        node = queue.remove()  # Retrieve node from the queue\n",
    "        if node.state == environment.goalstate:  # Goal state check\n",
    "            return build_path(node)\n",
    "        for action in range(environment.action_space.n):  # Look around\n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = Node(environment.sample(node.state, action), node, node.pathcost + 1, node.pathcost + 1)\n",
    "            queue.add(child)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(\"SmallMaze-v0\")\n",
    "env.render()\n",
    "solution = ucs(env)\n",
    "\n",
    "# Print path\n",
    "print(\"\\nSolution: {}\".format([env.state_to_pos(s) for s in solution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Heuristics\n",
    "\n",
    "Informed search requires a distance heuristic to be used in order to estimate the distance between a state and the goal. You already have at your disposal these functions:\n",
    "\n",
    "- *l1_norm(p1, p2)* - Computes the L1 norm (also known as the manhattan distance) between two points specified as tuples of coordinates\n",
    "- *l2_norm(p1, p2)* - Computes the L2 norm between two points specified as tuples of coordinates\n",
    "- *chebyshev(p1, p2)* - Computes the Chebyshev distance between two points specified as tuples of coordinates. Similar to L1 norm but diagonal moves are also considered\n",
    "\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm heuristic value: 6\n",
      "L2 norm heuristic value: 4.47213595499958\n",
      "Chebyshev heuristic value: 4\n"
     ]
    }
   ],
   "source": [
    "p1 = (0, 2)\n",
    "p2 = (4, 0)\n",
    "print(\"L1 norm heuristic value: {}\".format(Heu.l1_norm(p1, p2)))\n",
    "print(\"L2 norm heuristic value: {}\".format(Heu.l2_norm(p1, p2)))\n",
    "print(\"Chebyshev heuristic value: {}\".format(Heu.chebyshev(p1, p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Greedy Best-First Search\n",
    "\n",
    "The first assignment is to implement the Greedy-best-first search algorithm on **SmallMaze**. In particular, you are required to implement both *greedy_tree_search* and *greedy_graph_search* versions that will be called by the generic *greedy*. Use L1 norm as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by greedy must be in the following form (path, time_cost, space_cost), more in detail:\n",
    "\n",
    "- **path** - tuple of state identifiers forming a path from the start state to the goal state. None if no solution is found.\n",
    "- **time_cost** - the number of nodes checked during the exploration.\n",
    "- **space_cost** - the maximum number of nodes in memory at the same time.\n",
    "\n",
    "Functions to implement:\n",
    "- *greedy_tree_search(environment)*\n",
    "- *greedy_graph_search(environment)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_tree_search(environment, timeout=10000):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Tree search\n",
    "\n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "\n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    start_pos = environment.startstate\n",
    "\n",
    "    # Mahnattan distance.\n",
    "    heu = Heu.l1_norm(environment.state_to_pos(start_pos), goalpos)\n",
    "\n",
    "    # The node with STATE = problem.INITIAL-STATE.\n",
    "    first_node = Node(environment.startstate, None, 0, heu)\n",
    "    \n",
    "    # Create and initialize the frontier.\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.add(first_node)\n",
    "\n",
    "    time_cost = 0\n",
    "    space_cost = 1\n",
    "\n",
    "    while True:\n",
    "        # Timeout check.\n",
    "        if time_cost >= timeout:\n",
    "            return (\"time-out\", time_cost, space_cost)\n",
    "\n",
    "        # Check if EMPTY?(frontier).\n",
    "        if frontier.is_empty():\n",
    "            return None, time_cost, space_cost\n",
    "\n",
    "        # node <- POP(frontier).\n",
    "        node = frontier.remove()\n",
    "        time_cost += 1\n",
    "        space_cost -= 1\n",
    "\n",
    "        # Check if node.STATE is a problem.GOAL.\n",
    "        if node.state == environment.goalstate:\n",
    "            return build_path(node), time_cost, space_cost\n",
    "\n",
    "        # For each action in problem.ACTIONS(environment.ACTION-SPACE) (look around).\n",
    "        for action in range(environment.action_space.n):\n",
    "            next_move = environment.sample(node.state, action)\n",
    "            pos = environment.state_to_pos(next_move)\n",
    "            Heu.l1_norm(pos, goalpos)\n",
    "\n",
    "            # Path cost and euristic as node value.\n",
    "            child = Node(next_move, node, node.pathcost + 1, heu)\n",
    "\n",
    "            # frontier <- INSERT(child, frontier).\n",
    "            frontier.add(child)\n",
    "            space_cost += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_graph_search(environment):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Graph search\n",
    "\n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "\n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    start_pos = environment.startstate\n",
    "\n",
    "    # Mahnattan distance.\n",
    "    heu = Heu.l1_norm(environment.state_to_pos(start_pos), goalpos)\n",
    "\n",
    "    # The node with STATE = problem.INITIAL-STATE.\n",
    "    first_node = Node(environment.startstate, None, 0, heu)\n",
    "    \n",
    "    # Create and initialize the frontier.\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.add(first_node)\n",
    "    \n",
    "    # An empty set for child already explored.\n",
    "    explored = set()\n",
    "\n",
    "    time_cost = 0\n",
    "    space_cost = 1\n",
    "\n",
    "    while True:\n",
    "        # Check if EMPTY?(frontier).\n",
    "        if frontier.is_empty():\n",
    "            return None, time_cost, space_cost\n",
    "\n",
    "        # node <- POP(frontier).\n",
    "        node = frontier.remove()\n",
    "        space_cost -= 1\n",
    "        \n",
    "        # Check if it is a goal state.\n",
    "        if node.state == environment.goalstate:\n",
    "            return build_path(node), time_cost, space_cost\n",
    "\n",
    "        # Add node.STATE to explored.\n",
    "        explored.add(node.state)\n",
    "        space_cost += 1\n",
    "\n",
    "        # For each action in problem.ACTIONS(environment.ACTION-SPACE) (look around).\n",
    "        for action in range(environment.action_space.n):\n",
    "            next_move = environment.sample(node.state, action)\n",
    "            pos = environment.state_to_pos(next_move)\n",
    "            Heu.l1_norm(pos, goalpos)\n",
    "\n",
    "            # Path cost and euristic as node value.\n",
    "            child = Node(next_move, node, node.pathcost + 1, heu)\n",
    "\n",
    "            # Check if child.STATE is not in explored.\n",
    "            if (child.state not in explored):\n",
    "                # frontier <- INSERT(child, frontier).\n",
    "                frontier.add(child)\n",
    "                space_cost += 1\n",
    "\n",
    "            if frontier.frlen + len(explored) > space_cost:\n",
    "                space_cost = frontier.frlen + len(explored)\n",
    "                \n",
    "            time_cost += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function calls your implementations of greedy_tree_search and greedy_graph_search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(environment, search_type):\n",
    "    \"\"\"\n",
    "    Greedy-best-first search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        search_type: type of search - greedy_tree_search or greedy_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    path, time_cost, space_cost = search_type(environment)\n",
    "    return path, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search and graph search version of Greedy-best-first search and prints the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tGREEDY BEST FIRST TREE SEARCH PROBLEM: \n",
      "----------------------------------------------------------------\n",
      "Solution: time-out\n",
      "N° of nodes explored: 10000\n",
      "Max n° of nodes in memory: 30001\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\tGREEDY BEST FIRST GRAPH SEARCH PROBLEM: \n",
      "----------------------------------------------------------------\n",
      "Solution: [(0, 1), (1, 1), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "N° of nodes explored: 72\n",
      "Max n° of nodes in memory: 18\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"\n",
    "environment = gym.make(envname)\n",
    "\n",
    "solution_ts, time_ts, memory_ts = greedy(environment, greedy_tree_search)\n",
    "solution_gs, time_gs, memory_gs = greedy(environment, greedy_graph_search)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGREEDY BEST FIRST TREE SEARCH PROBLEM: \")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Solution: {}\".format(solution_2_string(solution_ts, environment)))\n",
    "print(\"N° of nodes explored: {}\".format(time_ts))\n",
    "print(\"Max n° of nodes in memory: {}\".format(memory_ts))\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGREEDY BEST FIRST GRAPH SEARCH PROBLEM: \")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Solution: {}\".format(solution_2_string(solution_gs, environment)))\n",
    "print(\"N° of nodes explored: {}\".format(time_gs))\n",
    "print(\"Max n° of nodes in memory: {}\".format(memory_gs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results can be found [here](lesson_2_results.txt).\n",
    "\n",
    "## Assignment 2: A* Search\n",
    "The second assignment is to implement the A search algorithm on SmallMaze. In particular, you are required to implement both astar_tree_search and astar_graph_search versions that will be called by the generic astar. Use L1 norm* as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by astar must be in the following form (path, time_cost, space_cost), more in detail:\n",
    "\n",
    "- **path** - tuple of state identifiers forming a path from the start state to the goal state. None if no solution is found.\n",
    "- **time_cost** - the number of nodes checked during the exploration.\n",
    "- **space_cost** - the maximum number of nodes in memory at the same time.\n",
    "\n",
    "Functions to implement:\n",
    "- *astar_tree_search(environment)*\n",
    "- *astar_graph_search(environment)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_tree_search(environment):\n",
    "    \"\"\"\n",
    "    A* Tree search\n",
    "\n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "\n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    start_pos = environment.startstate\n",
    "\n",
    "    # Mahnattan distance.\n",
    "    heu = Heu.l1_norm(start_pos, goalpos)\n",
    "    \n",
    "    # The node with STATE = problem.INITIAL-STATE.\n",
    "    first_node = Node(environment.startstate, None, 0, heu)\n",
    "    \n",
    "    # Create and initialize the frontier.\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.add(first_node)\n",
    "\n",
    "    time_cost = 0\n",
    "    space_cost = 1\n",
    "\n",
    "    while True:\n",
    "        # Check if EMPTY?(frontier).\n",
    "        if frontier.is_empty():\n",
    "            return None, time_cost, space_cost\n",
    "\n",
    "        # node <- POP(frontier).\n",
    "        node = frontier.remove()\n",
    "        time_cost += 1\n",
    "\n",
    "        # Check if node.STATE is a problem.GOAL.\n",
    "        if node.state == environment.goalstate:\n",
    "            return build_path(node), time_cost, space_cost\n",
    "\n",
    "        # For each action in problem.ACTIONS(environment.ACTION-SPACE) (look around).\n",
    "        for action in range(environment.action_space.n):\n",
    "            next_move = environment.sample(node.state, action)\n",
    "            pos = environment.state_to_pos(next_move)\n",
    "            heu = Heu.l1_norm(pos, goalpos)\n",
    "\n",
    "            # h = h* x g\n",
    "            child = Node(next_move, \n",
    "                         node, \n",
    "                         node.pathcost + 1, \n",
    "                         node.pathcost + heu + 1)\n",
    "            \n",
    "            # frontier <- INSERT(child, frontier).\n",
    "            frontier.add(child)\n",
    "\n",
    "            if frontier.frlen > space_cost:\n",
    "                space_cost = frontier.frlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_graph_search(environment):\n",
    "    \"\"\"\n",
    "    A* Graph search\n",
    "\n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "\n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    start_pos = environment.startstate\n",
    "\n",
    "    # Mahnattan distance.\n",
    "    heu = Heu.l1_norm(start_pos, goalpos)\n",
    "    \n",
    "    # The node with STATE = problem.INITIAL-STATE.\n",
    "    first_node = Node(environment.startstate, None, 0, heu)\n",
    "    \n",
    "    # Create and initialize the frontier.\n",
    "    queue = PriorityQueue()\n",
    "    queue.add(first_node)\n",
    "    \n",
    "    # An empty set for child already explored.\n",
    "    explored = set()\n",
    "    \n",
    "    time_cost = 0\n",
    "    space_cost = 1\n",
    "\n",
    "    while True:\n",
    "        # Check if EMPTY?(frontier).\n",
    "        if queue.is_empty():\n",
    "            return None, time_cost, space_cost\n",
    "\n",
    "        # node <- POP(frontier).\n",
    "        node = queue.remove()\n",
    "\n",
    "        # Add node.STATE to explored.\n",
    "        explored.add(node.state)\n",
    "        time_cost += 1\n",
    "\n",
    "        # Check if it is a goal state.\n",
    "        if node.state == environment.goalstate:\n",
    "            return build_path(node), time_cost, space_cost\n",
    "\n",
    "        # For each action in problem.ACTIONS(environment.ACTION-SPACE) (look around).\n",
    "        for action in range(environment.action_space.n):\n",
    "            next_move = environment.sample(node.state, action)\n",
    "            pos = environment.state_to_pos(next_move)\n",
    "            heu = Heu.l1_norm(pos, goalpos)\n",
    "\n",
    "            # f = h x g\n",
    "            child = Node(next_move, \n",
    "                         node, \n",
    "                         node.pathcost + 1, \n",
    "                         node.pathcost + heu + 1)\n",
    "\n",
    "            # Check if child.STATE is not in explored.\n",
    "            if child.state not in explored:\n",
    "                queue.add(child)\n",
    "\n",
    "                if queue.frlen > space_cost:\n",
    "                    space_cost = queue.frlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function calls your implementations of astar_tree_search and astar_graph_search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(environment, search_type):\n",
    "    \"\"\"\n",
    "    A* search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - astar_tree_search or astar_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    path, time_cost, space_cost = search_type(environment)\n",
    "    return path, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search and graph search version of A* search and prints the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tA* TREE SEARCH PROBLEM: \n",
      "----------------------------------------------------------------\n",
      "Solution: [(0, 1), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "N° of nodes explored: 2091\n",
      "Max n° of nodes in memory: 6271\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\tA* GRAPH SEARCH PROBLEM: \n",
      "----------------------------------------------------------------\n",
      "Solution: [(0, 1), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "N° of nodes explored: 22\n",
      "Max n° of nodes in memory: 5\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"\n",
    "environment = gym.make(envname)\n",
    "\n",
    "solution_ts, time_ts, memory_ts = astar(environment, astar_tree_search)\n",
    "solution_gs, time_gs, memory_gs = astar(environment, astar_graph_search)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tA* TREE SEARCH PROBLEM: \")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Solution: {}\".format(solution_2_string(solution_ts, environment)))\n",
    "print(\"N° of nodes explored: {}\".format(time_ts))\n",
    "print(\"Max n° of nodes in memory: {}\".format(memory_ts))\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tA* GRAPH SEARCH PROBLEM: \")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Solution: {}\".format(solution_2_string(solution_gs, environment)))\n",
    "print(\"N° of nodes explored: {}\".format(time_gs))\n",
    "print(\"Max n° of nodes in memory: {}\".format(memory_gs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results can be found [here](lesson_2_results.txt).\n",
    "\n",
    "### Discussion\n",
    "Now that you have correctly implemented both Greedy-best-first and A* what can you say about the solutions they compute? Are there significant differences in the stats? Try to play with other heuristics as well and see if your results change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
